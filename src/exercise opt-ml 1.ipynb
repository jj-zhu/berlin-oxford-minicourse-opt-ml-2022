{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629f2f5-417f-49ff-9481-48c9765c7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt_util import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35fc58-e038-4842-9e50-4c7eae13b5f8",
   "metadata": {},
   "source": [
    "# Implement GD for an (approximate) RKHS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e940693-3351-4a2c-a1a4-11bf5e0643a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some data\n",
    "sgd = 1\n",
    "n_x = 100  # num samples\n",
    "dim_x = 1\n",
    "\n",
    "data = np.random.uniform(-1, 1, size=[n_x, dim_x+1])\n",
    "X = 2 * np.pi * torch.from_numpy(data[:, 0]).float()\n",
    "Y = (torch.sin(X) + 0.4 * torch.rand_like(X, requires_grad=False)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3320cdf-774e-4259-8af7-b4f94b15e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model\n",
    "f_rf_1 = ml_model(model_class = 'rf', dim_x=dim_x, loss = torch.nn.MSELoss())\n",
    "optim_1 = torch.optim.SGD(f_rf_1.parameters, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3b365-116b-4ebb-8c56-67f5f7f624f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## carry out GD steps\n",
    "for iter_gd in range(1000):\n",
    "    # opt step\n",
    "    f_rf_1.train_step(x_th=X, y_th=Y, optimization=optim_1)\n",
    "\n",
    "    # for plotting\n",
    "    if iter_gd % 100 == 0:\n",
    "        print('iteration of GD:', iter_gd)\n",
    "        plt.figure()\n",
    "        plot_fitting(f_rf_1, X)\n",
    "        plt.scatter(x=X, y=Y)\n",
    "        plt.title(\"itertion:\" + str(iter_gd))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5f886-ced7-4a9b-b704-d75380f6d68b",
   "metadata": {},
   "source": [
    "# Implement SGD for the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322ed3f-2b84-4e79-b33f-ddd076c15bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define the model\n",
    "f_rf_sgd = ml_model(model_class = 'rf', dim_x=dim_x, loss = torch.nn.MSELoss())\n",
    "optim_sgd = torch.optim.SGD(f_rf_sgd.parameters, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed676a2c-9fac-4027-98fe-83ea992b7bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## carry out SGD steps\n",
    "for iter_gd in range(1000):\n",
    "    # opt step\n",
    "    id_rnd = # todo: let's randomly sample some indices from the dataset\n",
    "    f_rf_sgd.train_step(x_th=X[id_rnd], y_th=Y[id_rnd].reshape(-1,1), optimization=optim_sgd)\n",
    "\n",
    "    # for plotting\n",
    "    if iter_gd % 100 == 0:\n",
    "        print('iteration of GD:', iter_gd)\n",
    "        plt.figure()\n",
    "        plot_fitting(f_rf_sgd, X)\n",
    "        plt.scatter(x=X, y=Y)\n",
    "        plt.title(\"itertion:\" + str(iter_gd))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e6b67-f5b6-458f-a272-bc104c7b238a",
   "metadata": {},
   "source": [
    "# Implement an NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194424ec-84fc-4a70-b67c-b58776ce8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model\n",
    "f_nn = ml_model(model_class = 'nn', dim_x=dim_x, loss = torch.nn.MSELoss())\n",
    "optim_nn = torch.optim.SGD(f_nn.parameters, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e1aab-cf87-4d24-af24-fe15be62a859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## carry out SGD steps\n",
    "for iter_gd in range(10000):\n",
    "    # opt step\n",
    "    id_rnd = # todo: sgd, same as above\n",
    "    f_nn.train_step(x_th=X[id_rnd], y_th=Y[id_rnd].reshape(-1,1), optimization=optim_nn)\n",
    "\n",
    "    # for plotting\n",
    "    if iter_gd % 100 == 0:\n",
    "        print('iteration of GD:', iter_gd)\n",
    "        plt.figure()\n",
    "        plot_fitting(f_nn, X)\n",
    "        plt.scatter(x=X, y=Y)\n",
    "        plt.title(\"itertion:\" + str(iter_gd))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb148c1-c72c-4865-b698-fcc19511db3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Questions\n",
    "- [ ] Is there any benefits that SGD offers over GD?\n",
    "- [ ] Any downsides?\n",
    "- [ ] RKHS or NN? Why? Can RKHS (shallow) model behave badly?\n",
    "- [ ] Can you tune better features for RKHS functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a97cc2-5fed-482b-9268-9ec2e42be989",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "- Implement weight averaging: https://pytorch.org/docs/stable/optim.html#stochastic-weight-averaging\n",
    "- Play with the step size (learning rate). What are the best (better) values?\n",
    "- Does overfitting occur?\n",
    "- Can you load another dataset? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af732fbf-d498-460e-9218-3408964dc3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
